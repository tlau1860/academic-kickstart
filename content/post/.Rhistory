if (!require("bnlearn")) {install.packages("bnlearn"); require("bnlearn")}           ## Bayesian networks package
if (!require("network")) {install.packages("network"); require("network")}           ## basic network structures
if (!require("igraph")) {install.packages("igraph"); require("igraph")}              ## general network package
if (!require("HydeNet")) {install.packages("HydeNet"); require("HydeNet")}           ## Hybrid Bayesian networks
require("Rgraphviz")  ## if not installed, do
install.packages("HydeNet")
if (!require("bnlearn")) {install.packages("bnlearn"); require("bnlearn")}           ## Bayesian networks package
if (!require("network")) {install.packages("network"); require("network")}           ## basic network structures
if (!require("igraph")) {install.packages("igraph"); require("igraph")}              ## general network package
if (!require("HydeNet")) {install.packages("HydeNet"); require("HydeNet")}           ## Hybrid Bayesian networks
install.packages(c("bnlearn", "HydeNet", "igraph", "network"))
install.packages(c("bnlearn", "HydeNet", "igraph", "network"))
require("Rgraphviz")  ## if not installed, do
source("https://bioconductor.org/biocLite.R")
biocLite("Rgraphviz")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.11")
biocLite("Rgraphviz")
source("https://bioconductor.org/biocLite.R")
require("Rgraphviz")  ## if not installed, do
BiocManager::install("Rgraphviz")
Rogers <- na.omit(read.csv("http://www.people.fas.harvard.edu/~mair/datasets/OCDRogers.csv"))
head(Rogers)
# obtime ... time occupied by obsessive thoughts
# obinterfer ... interference due to obsessive thoughts
# obdistress ... distress associated with obsessive thoughts
# obresist ... resistance against obsessions
# obcontrol ... degree of control over obsessive thoughts
# comptime ... time spent performing compulsive behaviors
# compinterf ... interference due to compulsive behaviors
# compdis ... distress associated with compulsive behavior
# compresis ... resistance against compulsions
# compcont ... degree of control over compulsive behaviors
dim(Rogers)
ind <- c(rep(1,16), rep(2, 10))  ## depression/ocd item index
cormat <- cor(Rogers)
cormat                           ## fully connected network
if (!require("qgraph")) {install.packages("qgraph"); require("qgraph")}
dev.new()
qgraph(cormat, layout = "spring", minimum = 0.2,
graph = "cor", groups = list(Depression = 1:16, OCD = 17:26),
color = c("coral", "cadetblue"), labels = colnames(Rogers),
title = "OCD/Depression Correlation Network")
if (!require("qgraph")) {install.packages("qgraph"); require("qgraph")}
library(qgraph)
if (!require("mnormt")) {install.packages("mnormt"); require("mnormt")}
## --- quick Bayesian learning network fit:
Rogers1 <- as.data.frame(apply(Rogers, 2, as.numeric))
set.seed(123)
fitBN <- hc(Rogers1, restart = 10, perturb = 100) # hill-climbing
estrength <- arc.strength(fitBN, Rogers1, "bic-g")
if (!require("bnlearn")) {install.packages("bnlearn"); require("bnlearn")}           ## Bayesian networks package
fitBN <- hc(Rogers1, restart = 10, perturb = 100) # hill-climbing
fitBN
Rogers1
estrength <- arc.strength(fitBN, Rogers1, "bic-g")
x11(width = 15, height = 10)
strength.plot(fitBN, estrength, main = "Bayesian Network Depression/OCD", shape = "ellipse")
survey <- read.table("http://www.people.fas.harvard.edu/~mair/datasets/survey.txt", header = TRUE)
dim(survey)
head(survey)
dag <- empty.graph(nodes = c("A", "S", "E", "O", "R", "T"))  ## node specification
dag
## let's specify some arcs
arcmat <- matrix(c("A", "E", "S", "E", "E", "O", "E", "R", "O", "T", "R", "T"), byrow = TRUE, ncol = 2, dimnames = list(NULL, c("from", "to")))
arcmat                  ## edge list
arcs(dag) <- arcmat     ## adding arcs to the net
dag
graphviz.plot(dag)     ## plot the network; we see that there are no cycles --> DAG
dag.igraph <- igraph.from.graphNEL(as.graphNEL(dag))   ## convert into igraph object
is.dag(dag.igraph)  ## Is it a DAG?
if (!require("network")) {install.packages("network"); require("network")}           ## basic network structures
if (!require("igraph")) {install.packages("igraph"); require("igraph")}              ## general network package
if (!require("HydeNet")) {install.packages("HydeNet"); require("HydeNet")}           ## Hybrid Bayesian networks
dag.igraph <- igraph.from.graphNEL(as.graphNEL(dag))   ## convert into igraph object
is.dag(dag.igraph)  ## Is it a DAG?
## If we try to add an arc from T to E, bnlearn screams that it is not a DAG anymore; cycles introduced
try(set.arc(dag, from = "T", to = "E"))
## ------- d-separation (this is only related to the DAG, no data involved)
## various d-separation and path queries
dsep(dag, x = "S", y = "R")       ## are S and R independent? (no, they are conditional independent)
dsep(dag, x = "O", y = "R")       ## are O and R independent? (no, they are conditional independent)
bnlearn::path(dag, from = "S", to = "R")  ## is there a (indirect) path from S to R?
dsep(dag, x = "S", y = "R", z = "E") ## are S and R conditionally independent from E?
dsep(dag, x = "O", y = "R", z = "E") ## are O and R conditionally independent from E?
dsep(dag, "T", "E", c("O", "R"))     ## are T and E conditionally independent from O and R?
## compute local distributions by hand
head(survey)                       ## all variable categorical
survtab <- table(survey)           ## full frequency table (6-dimensional)
survtab
prod(dim(survtab)) - 1             ## number of parameters (pretty large for this small dataset)
P_A <- prop.table(table(survey[, "A"]))  ## age
P_A
P_S <- prop.table(table(survey[, "S"]))  ## sex
P_S
P_E_AS <- prop.table(table(survey[, c("E", "A", "S")]), c(2, 3))  ## education given age and sex (collider)
P_E_AS
P_O_E <- prop.table(table(survey[, c("O", "E")]), 2)    ## occupation given education (common cause)
P_O_E
P_R_E <- prop.table(table(survey[, c("R", "E")]), 2)    ## residence given education (common cause)
P_R_E
## Now we feed these probabilities into our DAG
plist <- list(A = P_A, S = P_S, E = P_E_AS, O = P_O_E, R = P_R_E, T = P_T_OR)
plist
P_T_OR <- prop.table(table(survey[, c("T", "O", "R")]), c(2, 3))  ## transportation given occupation and residence (collider)
P_T_OR
## Now we feed these probabilities into our DAG
plist <- list(A = P_A, S = P_S, E = P_E_AS, O = P_O_E, R = P_R_E, T = P_T_OR)
plist
bnfit1 <- custom.fit(dag, plist)       ## there is actually no computation going on here since we did all the hard work
bnfit1
nparams(bnfit1)                        ## we see that instead of 143 parameters we only have 21 (since we don't fit a saturated model)
## now let bn.fit do the job (i.e. computing all these probabilities)
## and check whether this leads to the same result
bnfit.mle <- bn.fit(dag, data = survey, method = "mle")  ## We're using ML estimation, nothing Bayesian so far
bnfit.mle
## Let's just extract the probability for E, given A and S, and compare to what we did by hand
bnfit.mle$E
P_E_AS         ## yep, they match!
## ------- Bayesian estimation
## Nothing Bayesian so far --> now we do it in a Bayesian way (uniform prior over node probabilities)
bnfit.bayes <- bn.fit(dag, data = survey, method = "bayes", iss = 10)
## iss stands for imaginary sample size and weights the influence of the prior (high values --> higher prior influence)
## We typically pick values between 1 and 15.
bnfit.bayes$O    ## check tables for O
bnfit.mle$O
## Are T and O conditionally independent given R?
ci.test("T", "O", "R", test = "x2", data = survey)  ## we don't need the net fit since this are just simple X2 computations
## H0: (conditional) independence
## can't reject H0, therefore we could remove O --> T using drop.arc()
dag2 <- drop.arc(dag, "O", "T")
graphviz.plot(dag2)
## compare original model with the new model using BIC
bnlearn::score(dag, data = survey, type = "bic")    ## compute BIC original structure
bnlearn::score(dag2, data = survey, type = "bic")   ## compute BIC modified structure
## Are T and E conditionally independent given O and R?
ci.test("T", "E", c("O", "R"), test = "x2", data = survey)
## Let's run a series of X2 tests reflecting the full network structure (original DAG)
arc.strength(dag, data = survey, criterion = "x2")
## Just for fun (for the moment), let the algorithm learn a network
set.seed(123)
learn.net <- hc(survey)     ## hc stands for hill-climbing and is a simple, fast heuristic
learn.net
graphviz.plot(learn.net)    ## that's not really meaningful (education influences sex??)
## compare the two graphs: original DAG vs. learned structure
bnlearn::score(dag, data = survey, type = "bic")
bnlearn::score(learn.net, data = survey, type = "bic")  ## better but non-sense
## we can also compute a BIC for each single arc
pathbic <- arc.strength(dag, data = survey, criterion = "bic")
pathbic
strength.plot(dag, pathbic)
## again, O --> T is the weakest connection, if this would be removed the overall BIC improves by ~10
## check: dag2 (O-T removed) vs. dag
bnlearn::score(dag2, data = survey, type = "bic") - bnlearn::score(dag, data = survey, type = "bic")
## ---- plotting the conditional distributions
bn.fit.dotplot(bnfit.bayes$T, main = "Travel", xlab = "P(T|O,R)", ylab = "")
## ----------------------------- Gaussian BNs -------------------------
## We start again with a hypothesis driven network.
## Let us just start with a simple network using the first 6 OCD symptoms and treating them as metric
Rogers1 <- as.data.frame(apply(Rogers, 2, as.numeric))
Rogsub <- Rogers1[, 17:22]
head(Rogsub)
op <- par(mfrow = c(2,3))
for (i in 1:6) barplot(table(Rogsub[, i]), xlab = colnames(Rogsub)[i])
par(op)
## Let's specify a simple network (probably complete nonsense from a clinical point of view)
dag <- model2network("[obtime][obinterfer][obdistress|obtime:obinterfer][obresist|obdistress][obcontrol|obdistress][comptime|obresist:obcontrol]")
dag
graphviz.plot(dag)
## We need to get the distribution parameters mu and sigma for the normal distributions for each node
reg.obtime <- lm(obtime ~ 1, data = Rogsub)                                               ## first top node
obtimepar <-  list(coef = coef(reg.obtime), sd = summary(reg.obtime)$sigma)
obtimepar
reg.obinterfer <- lm(obinterfer ~ 1, data = Rogsub)                                       ## second top node
obinterferpar <-  list(coef = coef(reg.obinterfer), sd = summary(reg.obinterfer)$sigma)
obinterferpar
reg.obdistress <- lm(obdistress ~ obtime + obinterfer, data = Rogsub)                     ## collider
obdistresspar <-  list(coef = coef(reg.obdistress), sd = summary(reg.obdistress)$sigma)
obdistresspar
reg.obresist <- lm(obresist ~ obdistress, data = Rogsub)                                  ## common cause
obresistpar <-  list(coef = coef(reg.obresist), sd = summary(reg.obresist)$sigma)
obresistpar
reg.obcontrol <- lm(obcontrol ~ obdistress, data = Rogsub)                                ## common cause
obcontrolpar <-  list(coef = coef(reg.obcontrol), sd = summary(reg.obcontrol)$sigma)
obcontrolpar
reg.comptime <- lm(comptime ~ obresist + obcontrol, data = Rogsub)                        ## collider
comptimepar <-  list(coef = coef(reg.comptime), sd = summary(reg.comptime)$sigma)
comptimepar
distlist <- list(obtime = obtimepar, obinterfer = obinterferpar, obdistress = obdistresspar,
obresist = obresistpar, obcontrol = obcontrolpar, comptime =  comptimepar)
distlist
gbn.fit <- custom.fit(dag, dist = distlist)   ## feed these parameters into the custom.fit function
gbn.fit
## Shortcut: Now we let bnlearn do the regression job; we just need to feed the graph structure and the data into the function
gbn.fit2 <- bn.fit(dag, data = Rogsub)
gbn.fit2
## just to check whether things match (selected nodes)
gbn.fit$obdistress
gbn.fit2$obdistress         ## yep!
gbn.fit$comptime
gbn.fit2$comptime           ## yep!
## ---- conditional independence test on partial correlations
ci.test(x = "comptime", y = "obdistress", z = "obcontrol", test = "cor", data = Rogsub)
## --- d-separability
dsep(dag, "obcontrol", "obresist", "obdistress")  ## obcontrol and obresist are d-separable (given obdistress)
## --- learning network
## Let the algorithm learn the structure
set.seed(123)
gbn.learn <- hc(Rogsub)
gbn.learn
graphviz.plot(gbn.learn)  ## that looks quite different
## check:
all.equal(dag, gbn.learn)  ## is this network equal to what we have proposed?
bnlearn::score(gbn.learn, data = Rogsub)
bnlearn::score(dag, data = Rogsub)
## ----------------------- Hybrid BNs --------------------
## Categorical and metric variables: Pulmonary Embolism Dataset
## Pulmonary embolism (PE) is a blockage of an artery in the lungs by a substance that
## has moved from elsewhere in the body through the bloodstream.
data(PE)
head(PE)
## ultimately, we'll be interested in the following 3 variables:
table(PE$death)
hist(PE$d.dimer, xlab = "diagnostic blood test", main = "D-Dimer Histogram")
barplot(table(PE$wells), xlab = "Wells")
PE <- transform(PE, wells = factor(wells))   ## categorize wells for prediction (see below)
## other variables in the network
table(PE$pe)
table(PE$pregnant)
table(PE$angio)
table(PE$treat)
## specify net
peNet <- HydeNetwork(~ wells +
pe | wells +
d.dimer | pregnant*pe +
angio | pe +
treat | d.dimer*angio +
death | pe*treat,
data = PE)
peNet
plot(peNet)    ## hypothesized network structure
## Nothing has been estimated so far, this is done using JAGS. The JAGS code is as follows
writeNetworkModel(peNet, pretty = TRUE)    ## includes parameters for single regressions
## We are interested in the following questions:
## -) what are the distributions for d-dimer and death for wells = 1
## -) what are the distributions for d-dimer and death for wells = 10
peNet_compiled1 <- compileJagsModel(peNet, n.chains = 2, data = list(wells = "1"))   ## compile JAGS code
peNet_compiled2 <- compileJagsModel(peNet, n.chains = 2, data = list(wells = "10"))   ## compile JAGS code
set.seed(123)
post1 <- HydeSim(peNet_compiled1, variable.names = c("d.dimer", "death"), n.iter = 10000, bind = FALSE)   ## MCMC sampling model 1
post2 <- HydeSim(peNet_compiled2, variable.names = c("d.dimer", "death"), n.iter = 10000, bind = FALSE)   ## MCMC sampling model 2
summary(post1$codas)
summary(post2$codas)
bp1 <- bindSim(post1)     ## bind posterior chains (merge the two chains into 1)
bp2 <- bindSim(post2)
## It gives us the marginal distributions for the two variables of interest:
## --- plot D-Dimer posterior
plot(density(bp1$d.dimer), xlim = c(100, 400), xlab = "posterior draws d-dimer", main = "Posterior Density D-Dimer (Wells = 1)", col = "cadetblue")
abline(v = mean(bp1$d.dimer), col = "cadetblue", lwd = 2)
lines(density(bp2$d.dimer), col = "salmon")
abline(v = mean(bp2$d.dimer), col = "salmon", lwd = 2)
legend("topright", legend = c("Wells = 1", "Wells = 10"), col = c("cadetblue", "salmon"), lty = 1)
par(op)
## --- plot death posterior
op <- par(mfrow = c(1,2))
barplot(table(bp1$death), xlab = "death", main = "Death Posterior (Wells = 1)", ylim = c(0, 20000))
barplot(table(bp2$death), xlab = "death", main = "Death Posterior (Wells = 2)", ylim = c(0, 20000))
par(op)
## Now let's learn a network on the full dataset:
Rogers1 <- as.data.frame(apply(Rogers, 2, as.numeric))
set.seed(123)
fitBN <- hc(Rogers1, restart = 10, perturb = 100)           ## hill climbing
## compute the edge strength
estrength <- arc.strength(fitBN, Rogers1, "bic-g")
head(estrength[order(estrength[,3]), ], 5)        ## the higher the absolute value, the more the arc contributes to model fit
x11(width = 15, height = 10)
strength.plot(fitBN, estrength, main = "Bayesian Network Depression/OCD", shape = "ellipse")
## let's do the same thing once more
fitBN2 <- hc(Rogers1, restart = 10, perturb = 100)
estrength <- arc.strength(fitBN2, Rogers1, "bic-g")
head(estrength[order(estrength[,3]), ], 5)
x11(width = 15, height = 10)
strength.plot(fitBN2, estrength, main = "Bayesian Network Depression/OCD", shape = "ellipse")
## let's check
all.equal(fitBN, fitBN2)
bnlearn::compare(target = fitBN, current = fitBN2)
## number of true positives (tp, the number of arcs in current also present in target),
## number of false positives (fp, the number of arcs in current not present in target) and
## number of false negatives (fn, the number of arcs not in current but present in target)
bnlearn::compare(target = fitBN, current = fitBN2, arcs = TRUE)   ## same at arc level
bnlearn::graphviz.compare(fitBN, fitBN2)                          ## produces the plot
## --- bootstrap and model averaging (takes 1 min)
## we use 500 bootstrap samples
set.seed(123)
bootnet <- boot.strength(Rogers1, R = 500, algorithm = "hc")
head(bootnet)
bootnet
## Now let's average across the 500 networks
avgnet <- averaged.network(bootnet)
## plot I: using the BIC arc strength
estrength <- arc.strength(avgnet, Rogers1, "bic-g")
x11(width = 15, height = 10)
strength.plot(avgnet, estrength, shape = "ellipse")
## plot II: using the direction strength as arc thickness
estrength2 <- bootnet   ## table with direction probabilities
estrength2$strength <- estrength2$direction  ## use the direction probabilities for edge width
head(estrength2)
x11(width = 15, height = 10)
strength.plot(avgnet, estrength2, shape = "ellipse")
## --------------------- Constraint-based structure learning algorithm (incremental association)
## using the IAMB algorithm
fitIAMB <- iamb(Rogers1)
fitIAMB                      ## 14 undirected edges, 36 directed
x11(width = 15, height = 10)
g1 <- graphviz.plot(fitIAMB)       ## we see that we have directed and undirected edges
x11(width = 15, height = 10)       ## make it a bit more readable
plot(g1, attrs = list(node = list(fontsize = 30, fillcolor = "bisque")))  ## bidirectional edges instead of undirected
